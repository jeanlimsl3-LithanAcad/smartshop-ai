# backend/smartshop/ai_client.py

import os
import logging
from openai import OpenAI

logger = logging.getLogger(__name__)

# Get API key from environment (settings already load .env)
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# Create client (if key is missing, this will be None but we handle it below)
client = OpenAI(api_key=OPENAI_API_KEY) if OPENAI_API_KEY else None

# Model used for this project
DEFAULT_MODEL = "gpt-4o-mini"


def generate_ai_text(user_prompt: str, system_instruction: str | None = None) -> str:
    """
    Try to call OpenAI. If anything fails (no key, network error, etc.),
    return a safe fallback message so the API still returns 200 OK.

    This is ideal for classroom / demo environments.
    """

    # Generic fallback message for when real AI is not available
    fallback = (
        "This is a SmartShop demo response. In production, this text would be "
        "generated by the OpenAI model based on your request: "
        f'\"{user_prompt}\"'
    )

    # If no key or client, immediately fall back
    if not OPENAI_API_KEY or client is None:
        logger.warning("OPENAI_API_KEY missing or client not initialised; using fallback response.")
        return fallback

    # Build messages for the chat completion API
    messages = []
    if system_instruction:
        messages.append({"role": "system", "content": system_instruction})
    messages.append({"role": "user", "content": user_prompt})

    try:
        response = client.chat.completions.create(
            model=DEFAULT_MODEL,
            messages=messages,
            temperature=0.4,
        )
        return response.choices[0].message.content.strip()

    except Exception as e:
        # Log the real error to the console, but do NOT break the API
        logger.exception("Error calling OpenAI; falling back to demo response.")
        return fallback
